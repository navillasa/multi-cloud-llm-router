# GCP-specific configuration for LLM server

model:
  uri: "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.q4_k_m.gguf"
  path: "/models/tinyllama.gguf"
  storageClass: "standard-rwo"
  storageSize: "10Gi"

ingress:
  hosts:
    - host: gcp.llm.yourdomain.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: llm-server-tls-gcp
      hosts:
        - gcp.llm.yourdomain.com

cloud:
  provider: "gcp"
  region: "us-central1"
  costPerHour: 0.0475  # e2-standard-2 SPOT instance price in us-central1
