# AWS-specific configuration for LLM server

model:
  uri: "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.q4_k_m.gguf"
  path: "/models/tinyllama.gguf"
  storageClass: "gp2"
  storageSize: "10Gi"

ingress:
  hosts:
    - host: aws.llm.yourdomain.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: llm-server-tls-aws
      hosts:
        - aws.llm.yourdomain.com

cloud:
  provider: "aws"
  region: "us-west-2"
  costPerHour: 0.0928  # t3.large on-demand price in us-west-2
